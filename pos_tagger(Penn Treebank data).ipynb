{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pos_tagger(Penn Treebank data).ipynb","provenance":[],"authorship_tag":"ABX9TyONv41wZbEwY4UnQUafGDzv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08zrvh3EE9Aq","executionInfo":{"status":"ok","timestamp":1611629789020,"user_tz":-330,"elapsed":28664,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"06655f69-d20d-40f1-a435-513d11d90feb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9HILTMjgC7M","executionInfo":{"status":"ok","timestamp":1611629793917,"user_tz":-330,"elapsed":33554,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"33fb5542-6774-4578-e789-3f9cd3801b08"},"source":["!pip install sklearn_crfsuite"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting sklearn_crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 4.1MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sk0MFs9iG8Ng","executionInfo":{"status":"ok","timestamp":1611629795876,"user_tz":-330,"elapsed":35505,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"9292ceee-0fb6-4696-a1b5-02707fcc3926"},"source":["## import libraries\n","import nltk\n","\n","## download pos tagging annotated dataset from nltk\n","nltk.download('treebank')\n","\n","## load datset \n","from nltk.corpus import treebank\n","import re\n","import warnings \n","warnings.filterwarnings('ignore')\n","from sklearn_crfsuite import CRF\n","from sklearn_crfsuite import metrics, scorers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/treebank.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Zm21GYILf7t"},"source":["## Popular datasets for pos tagging \n","\n","\n","1.  Penn Treebank \n","2.  Universal Dependencies\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2sJK90dHvbl","executionInfo":{"status":"ok","timestamp":1611629797209,"user_tz":-330,"elapsed":36832,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"47d1ae15-b3a7-4c61-a2a6-3221de14fdaa"},"source":["## extract words and associated tags from penn treebank dataset\n","penn_treebank_pos_dataset = []\n","for fileid in treebank.fileids():\n","  tokens = []\n","  tags = []\n","  for word, tag in treebank.tagged_words(fileid):\n","    tokens.append(word)\n","    tags.append(tag)\n","  penn_treebank_pos_dataset.append((tokens,tags))\n","print(f\"First sentence :- \\n {penn_treebank_pos_dataset[0]}\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["First sentence :- \n"," (['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.', 'Mr.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', ',', 'the', 'Dutch', 'publishing', 'group', '.'], ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.', 'NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP', ',', 'DT', 'NNP', 'VBG', 'NN', '.'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CG2Vc2LyMiCB","executionInfo":{"status":"ok","timestamp":1611629797212,"user_tz":-330,"elapsed":36831,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"205c93e8-4d82-4169-9334-189eb673eb8d"},"source":["## split whole dataset into train and test datasets\n","train_dataset_size = int(0.8*len(penn_treebank_pos_dataset)) ## taken 80% of data as traning dataset\n","penn_treebank_training_dataset = penn_treebank_pos_dataset[:train_dataset_size]\n","penn_treebank_testing_dataset = penn_treebank_pos_dataset[train_dataset_size:]\n","\n","print(f\"Size of Penn treebank training dataset :- {len(penn_treebank_training_dataset)}\")\n","print(f\"Size of Penn treebank testing dataset :- {len(penn_treebank_testing_dataset)}\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Size of Penn treebank training dataset :- 159\n","Size of Penn treebank testing dataset :- 40\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oDwIDjFnOkQP","executionInfo":{"status":"ok","timestamp":1611629797212,"user_tz":-330,"elapsed":36826,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}}},"source":["## extract features from every word in the sentence\n","def extract_word_features(sentence, index):\n","  return {\n","      'word':sentence[index],\n","      'is_first':index==0,\n","      'is_last':index ==len(sentence)-1,\n","      'is_capitalized':sentence[index][0].upper() == sentence[index][0],\n","      'is_all_caps': sentence[index].upper() == sentence[index],\n","      'is_all_lower': sentence[index].lower() == sentence[index],\n","      'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n","      'prefix-1':sentence[index][0],\n","      'prefix-2':sentence[index][:2],\n","      'prefix-3':sentence[index][:3],\n","      'prefix-3':sentence[index][:4],\n","      'suffix-1':sentence[index][-1],\n","      'suffix-2':sentence[index][-2:],\n","      'suffix-3':sentence[index][-3:],\n","      'suffix-3':sentence[index][-4:],\n","      'prev_word':'' if index == 0 else sentence[index-1],\n","      'next_word':'' if index < len(sentence) else sentence[index+1],\n","      'has_hyphen': '-' in sentence[index],\n","      'is_numeric': sentence[index].isdigit(),\n","      'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n","      }"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XxJCbA8vNXf3","executionInfo":{"status":"ok","timestamp":1611629797213,"user_tz":-330,"elapsed":36822,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}}},"source":["## creating dataset from raw dataset with all word features\n","def transform_rawdata_dataset_format(tagged_sentences):\n","  X,y = [],[]\n","  for sentence, tags in tagged_sentences:\n","    sent_word_features, sent_tags = [], []\n","    for index in range(len(sentence)):\n","      sent_word_features.append(extract_word_features(sentence=sentence, index=index))\n","      sent_tags.append(tags[index])\n","    X.append(sent_word_features)\n","    y.append(sent_tags)\n","  return X,y"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAfzB9SrNdJu","executionInfo":{"status":"ok","timestamp":1611629797615,"user_tz":-330,"elapsed":37220,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}}},"source":["## create train, test datasets of features and target variables\n","X_penn_train, y_penn_train = transform_rawdata_dataset_format(penn_treebank_training_dataset)\n","X_penn_test, y_penn_test = transform_rawdata_dataset_format(penn_treebank_testing_dataset)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLCBoao_QvHK","executionInfo":{"status":"ok","timestamp":1611629797616,"user_tz":-330,"elapsed":37216,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}}},"source":["## initialize CRF model\n","penn_treebank_crf = CRF(algorithm='lbfgs',\n","                        c1=0.01,\n","                        c2=0.1,\n","                        max_iterations= 100,\n","                        all_possible_transitions = True)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PsMsxRVRlNr","executionInfo":{"status":"ok","timestamp":1611629877810,"user_tz":-330,"elapsed":117405,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"22f5f980-0212-4f4d-8b7f-7545fd677d15"},"source":["## training a model\n","print(\"Starting CRF model traing on Penn Treebank dataset \")\n","penn_treebank_crf.fit(X_penn_train, y_penn_train)\n","print(\"Completed CRF model traning on Penn Treebank Dataset sucessfully\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Starting CRF model traing on Penn Treebank dataset \n","Completed CRF model traning on Penn Treebank Dataset sucessfully\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_bqyfAiR4Lq","executionInfo":{"status":"ok","timestamp":1611629880364,"user_tz":-330,"elapsed":119953,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"1899afea-1325-4fe2-9f78-58d969240e1e"},"source":["## evaluate CRF model on test dataset\n","y_penn_predict_test_results =  penn_treebank_crf.predict(X_penn_test)\n","print(\"F1-score on test dataset \")\n","f1_score_testdata = metrics.flat_f1_score(y_penn_test, y_penn_predict_test_results, average='weighted', labels=penn_treebank_crf.classes_)\n","print(f1_score_testdata)\n","\n","## evaluate CRF model on training dataset\n","y_penn_predict_train_results =  penn_treebank_crf.predict(X_penn_train)\n","print(\"F1-score on train dataset \")\n","f1_score_testdata = metrics.flat_f1_score(y_penn_train, y_penn_predict_train_results, average='weighted', labels=penn_treebank_crf.classes_)\n","print(f1_score_testdata)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["F1-score on test dataset \n","0.9668646324625245\n","F1-score on train dataset \n","0.9936643188628935\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LaNzyPZUCLn","executionInfo":{"status":"ok","timestamp":1611629880365,"user_tz":-330,"elapsed":119948,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"7c359769-fca9-4cc4-f620-e23e6c3593d5"},"source":["## classification report\n","print(\"Class wise score:\")\n","print(metrics.flat_classification_report(\n","    y_penn_test, y_penn_predict_test_results, labels=penn_treebank_crf.classes_, digits=3\n","))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Class wise score:\n","              precision    recall  f1-score   support\n","\n","         NNP      0.952     0.963     0.957      1213\n","           ,      1.000     1.000     1.000       592\n","          CD      1.000     0.999     0.999       683\n","         NNS      0.964     0.986     0.975       740\n","          JJ      0.879     0.912     0.895       731\n","          MD      0.993     1.000     0.996       135\n","          VB      0.980     0.946     0.963       313\n","          DT      0.992     0.993     0.992      1062\n","          NN      0.962     0.955     0.958      1899\n","          IN      0.981     0.980     0.981      1285\n","           .      1.000     1.000     1.000       509\n","         VBZ      0.958     0.936     0.947       219\n","         VBG      0.936     0.876     0.905       185\n","          CC      1.000     0.997     0.998       287\n","         VBD      0.965     0.945     0.955       492\n","         VBN      0.917     0.907     0.912       279\n","      -NONE-      0.998     1.000     0.999       871\n","          RB      0.912     0.912     0.912       296\n","          TO      1.000     1.000     1.000       298\n","         PRP      1.000     1.000     1.000       150\n","         RBR      0.375     0.231     0.286        13\n","         WDT      0.954     1.000     0.976        62\n","         VBP      0.878     0.902     0.890       112\n","          RP      0.667     0.720     0.692        25\n","        PRP$      1.000     1.000     1.000        74\n","         JJS      0.960     1.000     0.980        24\n","         POS      0.992     1.000     0.996       124\n","          ``      1.000     1.000     1.000        55\n","          EX      0.750     1.000     0.857         3\n","          ''      1.000     1.000     1.000        52\n","          WP      1.000     1.000     1.000        13\n","           :      1.000     1.000     1.000        49\n","         JJR      0.764     0.894     0.824        47\n","         WRB      1.000     0.955     0.977        22\n","           $      1.000     1.000     1.000       170\n","        NNPS      0.739     0.459     0.567        37\n","         WP$      1.000     1.000     1.000         4\n","       -LRB-      1.000     1.000     1.000        16\n","       -RRB-      1.000     1.000     1.000        16\n","         PDT      0.000     0.000     0.000         4\n","         RBS      1.000     1.000     1.000         1\n","          FW      0.000     0.000     0.000         0\n","          UH      0.000     0.000     0.000         0\n","         SYM      0.000     0.000     0.000         0\n","          LS      0.000     0.000     0.000         0\n","           #      0.000     0.000     0.000         0\n","\n","   micro avg      0.967     0.967     0.967     13162\n","   macro avg      0.814     0.814     0.813     13162\n","weighted avg      0.967     0.967     0.967     13162\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EcKF2OPE6IxA"},"source":["Number Tag Description\n","1.\tCC\tCoordinating conjunction\n","2.\tCD\tCardinal number\n","3.\tDT\tDeterminer\n","4.\tEX\tExistential there\n","5.\tFW\tForeign word\n","6.\tIN\tPreposition or subordinating conjunction\n","7.\tJJ\tAdjective\n","8.\tJJR\tAdjective, comparative\n","9.\tJJS\tAdjective, superlative\n","10.\tLS\tList item marker\n","11.\tMD\tModal\n","12.\tNN\tNoun, singular or mass\n","13.\tNNS\tNoun, plural\n","14.\tNNP\tProper noun, singular\n","15.\tNNPS\tProper noun, plural\n","16.\tPDT\tPredeterminer\n","17.\tPOS\tPossessive ending\n","18.\tPRP\tPersonal pronoun\n","19.\tPRP\tPossessive pronounRB\tAdverb\n","21.\tRBR\tAdverb, comparative\n","22.\tRBS\tAdverb, superlative\n","23.\tRP\tParticle\n","24.\tSYM\tSymbol\n","25.\tTO\tto\n","26.\tUH\tInterjection\n","27.\tVB\tVerb, base form\n","28.\tVBD\tVerb, past tense\n","29.\tVBG\tVerb, gerund or present participle\n","30.\tVBN\tVerb, past participle\n","31.\tVBP\tVerb, non-3rd person singular present\n","32.\tVBZ\tVerb, 3rd person singular present\n","33.\tWDT\tWh-determiner\n","34.\tWP\tWh-pronoun\n","35.\tWP$\tPossessive wh-pronoun\n","36.\tWRB\tWh-adverb"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UR_C9Dz4VS8B","executionInfo":{"status":"ok","timestamp":1611629880366,"user_tz":-330,"elapsed":119943,"user":{"displayName":"sharmila projects","photoUrl":"","userId":"06535329016763322144"}},"outputId":"a8e4799d-9936-419a-c4a1-d0d644fab025"},"source":["## apply trained model on new text data\n","example_sentence = \"The tagger produced good results\"\n","word_features = [extract_word_features(example_sentence.split(), index) for index in range(len(example_sentence.split()))]\n","results = penn_treebank_crf.predict_single(word_features)\n","penn_tups = [(example_sentence.split()[index], results[index]) for index in range(len(example_sentence.split()))]\n","print(penn_tups)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[('The', 'DT'), ('tagger', 'NN'), ('produced', 'VBN'), ('good', 'JJ'), ('results', 'NNS')]\n"],"name":"stdout"}]}]}